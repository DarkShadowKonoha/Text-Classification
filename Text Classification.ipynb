{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Inbuilt Naive Bayes Classifier - MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Various models required\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "import os,sys\n",
    "from sklearn import model_selection\n",
    "import re,string\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset Used can be downloaded from below link\n",
    "#http://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups\n",
    "\n",
    "#X is a list further made in form of tuple , \n",
    "# where first element is name of document and second is the text in documents.\n",
    "#Y is the list of category\n",
    "\n",
    "#change the path of dataset according to the your respective path\n",
    "X  =[] \n",
    "Y = []\n",
    "for category in os.listdir(\"Datasets\"):\n",
    "    for document in os.listdir(\"Datasets/\"+category):\n",
    "        with open(\"Datasets/\"+category+'/'+document, \"r\") as f:\n",
    "            X.append((document,f.read()))\n",
    "            Y.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'tuple'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#DataType of X and Y in detail\n",
    "print(type(X))\n",
    "print(type(X[0]))\n",
    "print(type(X[0][0]))\n",
    "print(type(X[0][1]))\n",
    "print(type(Y))\n",
    "#We can notice that it is a tuple\n",
    "#the tuple has its first element as name of document and second element as text of document.\n",
    "# Remove comment in the following lines to check output and get more familiar with data\n",
    "\n",
    "# print(X[0][1])\n",
    "# print(X[1][1])\n",
    "# print(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data in training and testing\n",
    "x_train,x_test,y_train,y_test=model_selection.train_test_split(X,Y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14997\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "#split has done in nearly 3:1 ratio\n",
    "#you can change the ratio of spliting by passing a argumnent in train_test_split() i.e, test_size\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hey', 'I', 'am', 'Anshika', 'I', 'am', 'superb', 'What', 'are', 'you', 'doing', 'there', '']\n"
     ]
    }
   ],
   "source": [
    "#Using RegEx to split the text into seprate words \n",
    "#Example for showing re.split\n",
    "sample_text=\"Hey! I am Anshika. I am superb. What are you doing there?\"\n",
    "print(re.split(r'\\W+',sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop Words : words that are common in all type of text documents,\n",
    "#they don't help us in finding the probability as they are common in every category\n",
    "#This are stop_words in common taken from intenet.\n",
    "stop_word=[\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\n",
    "\"by\",\"could\",\"did\",\"do\",\"does\",\"doing\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"has\",\"have\",\"having\",\"he\",\"he'd\",\"he'll\",\"he's\",\"her\",\n",
    "\"here\",\"here's\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"how's\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"if\",\"in\",\"into\",\"is\",\"it\",\"it's\",\"its\",\"itself\",\"let's\",\"me\",\n",
    "\"more\",\"most\",\"my\",\"myself\",\"nor\",\"of\",\"on\",\"once\",\"only\",\"or\",\"other\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"same\",\"she\",\n",
    "\"she'd\",\"she'll\",\"she's\",\"should\",\"so\",\"some\",\"such\",\"than\",\"that\",\"that's\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"there's\",\n",
    "\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"very\",\"was\",\"we\",\"we'd\",\n",
    "\"we'll\",\"we're\",\"we've\",\"were\",\"what\",\"what's\",\"when\",\"when's\",\"where\",\"where's\",\"which\",\"while\",\"who\",\"who's\",\"whom\",\"why\",\"why's\",\"with\",\n",
    "\"would\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making Dictionary of words with their corresponding frequency\n",
    "dicn={}\n",
    "for i in range(len(x_train)):\n",
    "    #Took [1] because [0] is name of document and [1] is text in doc\n",
    "    word=x_train[i][1].lower()\n",
    "    #splitting the text into seprate words\n",
    "    stripped=re.split(r'\\W+',word)\n",
    "    #Iterating over each word\n",
    "    for s in stripped:\n",
    "        #we will not include stop_words, alpha-numerics, punctuations or irrelevant word of length less than 2 in our dictionary\n",
    "        if not(s.isalpha()) or s in stop_word or len(s)<=2:\n",
    "            continue\n",
    "        if s in dicn:\n",
    "            dicn[s]+=1\n",
    "        else:\n",
    "            dicn[s]=1\n",
    "            \n",
    "# Remove comment from below to print the dictionary that we created\n",
    "# dicn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting the dictionary on basis of frequency of words in descending order\n",
    "#you can read more about itemgetter using help(operator.itemgetter)\n",
    "\n",
    "sorted_dicn = sorted(dicn.items(), key=operator.itemgetter(1),reverse=True)\n",
    "# sorted_dicn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting graph on no. of words vs corresponding frequency\n",
    "#On basis of graph we can decide the number of features(words) we want to take\n",
    "features=sorted_dicn\n",
    "ft_list=[]\n",
    "ft_list_freq=[]\n",
    "for i in range(len(features)):\n",
    "    ft_list.append(i)\n",
    "    ft_list_freq.append(features[i][1])\n",
    "plt.plot(ft_list,ft_list_freq)\n",
    "plt.axis([0,8000,1,5000])\n",
    "plt.grid()\n",
    "plt.show()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We decided to take top 2000 words with max freuqency as our feature\n",
    "#here feature list is ft_list\n",
    "ft_list=[features[i][0] for i in range(2000)]\n",
    "\n",
    "# Remove comment to take a look at 2000 words we selected\n",
    "# ft_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making x_train dataset\n",
    "#No. of rows is equivalent to rows in x_train, and column is equal to length of ft_list(feature list)\n",
    "x_train_dataset=np.zeros([len(x_train),len(ft_list)],int)\n",
    "for i in range(len(x_train)):\n",
    "    words=x_train[i][1].lower()\n",
    "    word=re.split(r'\\W+',words)\n",
    "    #Iterating over each word\n",
    "    for j in word:\n",
    "        #We will add the frequency corresponding to that word only which is in our ft_list(feature list)\n",
    "        if j in ft_list:\n",
    "            x_train_dataset[i][ft_list.index(j)]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making x_test dataset\n",
    "#No. of rows is equivalent to rows in x_test, and column is equal to length of answer1(feature list)\n",
    "x_test_dataset=np.zeros([len(x_test),len(ft_list)],int)\n",
    "for i in range(len(x_test)):\n",
    "    words=x_test[i][1].lower()\n",
    "    word=re.split(r'\\W+',words)\n",
    "    #Iterating over each word\n",
    "    for j in word:\n",
    "        #We will add the frequency corresponding to that word only which is in our answer1(feature list)\n",
    "        if j in ft_list:\n",
    "            x_test_dataset[i][ft_list.index(j)]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing x_train and x_test dataset \n",
    "# print(x_train_dataset)\n",
    "# print(\"--------------------------\")\n",
    "# print(x_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training data: 0.8933786757351471\n",
      "Score on testing data: 0.8558\n"
     ]
    }
   ],
   "source": [
    "#Demonstrating confusion-matrix and classification report\n",
    "clf=MultinomialNB()\n",
    "clf.fit(x_train_dataset,y_train)\n",
    "y_pred=clf.predict(x_test_dataset)\n",
    "print(\"Score on training data:\",clf.score(x_train_dataset,y_train))\n",
    "print(\"Score on testing data:\",clf.score(x_test_dataset,y_test))\n",
    "\n",
    "# Remove comments from below if you want to take a look at confusion Matrix and and classification report\n",
    "\n",
    "# print(confusion_matrix(y_test,y_pred))\n",
    "# print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Implementation of Naive Baye's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making dictionary for implementing Naive Baye's\n",
    "def fit(x_train_dataset,y_train):\n",
    "    count={}\n",
    "    total_word=0\n",
    "    y_train=np.array(y_train)\n",
    "    #Total no. of documents is calculated\n",
    "    count[\"total_doc\"]=len(y_train)\n",
    "    classes=set(y_train)\n",
    "    for i in classes:\n",
    "        temp=0\n",
    "        #selecting x_train corresponding to class present in y_train\n",
    "        x_train_with_i=x_train_dataset[y_train==i]\n",
    "        #finding length of data with category corresponding to i \n",
    "        temp2=x_train_with_i.shape[0]\n",
    "        count[i]={}\n",
    "        #Iterating over ft_list(actual feature list)\n",
    "        for feature in ft_list:\n",
    "            #Calculating total word in feature\n",
    "            l=(x_train_with_i[:,ft_list.index(feature)]).sum()\n",
    "            count[i][feature]=l\n",
    "            temp+=l\n",
    "        #Total word in that class\n",
    "        count[i][\"word_in_class\"]=temp\n",
    "        #Length of data with y_train belonging to specific class\n",
    "        count[i][\"length\"]=temp2\n",
    "        \n",
    "    \n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(x_test,dic,classes):\n",
    "    prob=np.log(dic[classes][\"length\"])-np.log(dic[\"total_doc\"])\n",
    "    feature=list(dic[classes].keys())\n",
    "    #-2 is done becuase there will be \"length\" and \"word in class\" present in feature. \n",
    "    for j in range (len(feature)-2):\n",
    "        xj=x_test[j]\n",
    "        #If frequency is 0, we will not consider it\n",
    "        if xj==0:\n",
    "            current_prob=0\n",
    "        else:\n",
    "            #Extra addition part is Laplace correction\n",
    "            num=dic[classes][feature[j]]+1\n",
    "            den=dic[classes][\"word_in_class\"]+len(dic[classes].keys())-2\n",
    "            current_prob=np.log(num)-np.log(den)\n",
    "        prob+=current_prob\n",
    "    return prob\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best_class or probable answer will be returned from here\n",
    "def predict_for_single(x_test,dic):\n",
    "    first_run=True\n",
    "    classes=dic.keys()\n",
    "    for i in classes:\n",
    "        if i==\"total_doc\":\n",
    "            continue\n",
    "        prob=probability(x_test,dic,i)\n",
    "        if first_run or prob>best_prob:\n",
    "            best_prob=prob\n",
    "            first_run=False\n",
    "            best_class=i\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_(x_test,dic):\n",
    "    y_pred=[]\n",
    "    for x in x_test:\n",
    "        y_pred.append(predict_for_single(x,dic))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y_test,y_pred):\n",
    "        count = 0\n",
    "        for i in range(len(y_pred)):\n",
    "            if y_pred[i] == y_test[i]:\n",
    "                count+=1\n",
    "        return count/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell will take time to execute\n",
    "dictionary=fit(x_train_dataset,y_train)\n",
    "y_pred=predict_(x_test_dataset,dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on testing_data: 0.8722\n"
     ]
    }
   ],
   "source": [
    "print(\"Score on testing_data:\",score(y_test,y_pred))\n",
    "\n",
    "# Remove comments from below if you want to take a look at confusion Matrix and and classification report\n",
    "# print(confusion_matrix(y_test,y_pred))\n",
    "# print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
